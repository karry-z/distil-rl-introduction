# 第0章. 前言

## 关于本教程

作为一名自学强化学习（RL）的学习者，我一直在寻找恰到好处的学习资料。市面上有很多优质资源，但大多数要么直接深入高级算法，要么未能以初学者易于理解的方式串联起各个概念。

Richard Sutton的《*Reinforcement Learning: An Introduction*》（以下简称RL入门书）被公认为强化学习领域的圣经。不可否认，这是一部绝佳的学习资源，但通读全书需要投入大量精力。事实上，大多数学习者——无论是研究人员还是实践者——并不需要掌握书中的所有细节，就能理解核心思想、学习经典算法，并开始应用甚至开发新算法。

这正是我创建本教程的初衷。在阅读RL入门书并整理学习笔记的过程中，我开始思考：是否存在一种更快捷、高效的方式，能让读者无需逐字阅读全书，就能吸收其中的关键知识？于是，这个项目应运而生——一个基于RL入门书的精简版强化学习"知识库"。

我从原书中**精心挑选了最核心的章节，帮助您构建扎实的知识基础**。我参考了由Sutton研究团队成员开设的[Coursera专项课程](https://www.coursera.org/specializations/reinforcement-learning)的结构。这个知识库融合了RL入门书和在线课程的精华，根据我的学习经验在两种形式间灵活切换，为您提供最便捷的学习路径。

**本教程始于我的个人笔记**，我为每个章节添加了介绍性说明，并优化了内容的逻辑流程，使其更易于理解。不过说实话——我并不认为自己是这个项目的"作者"，而更像是"知识整理者"。因此，我非常欢迎您提出任何反馈，帮助改进本教程的质量！

## 阅读指南

- **本教程的结构**

  本教程的章节是根据配套的Coursera课程结构精心筛选和重新组织的。一个明显的差异是，我移除了RL入门书中的第7章"n步自举法" (本章无限期停更中...)。

  选定的章节按照RL入门书的分类方式，分为两大类：**表格型解决方案**和**近似型解决方案**。您可以在主页或侧边栏中找到这些分类，方便导航。

  下一章将对强化学习（RL）进行快速介绍。第2章至第7章专注于*表格型设置*下的强化学习。从第8章开始，我们将重点转向函数近似方法。最后一章并非来自RL入门书——这是我额外添加的内容，旨在介绍强化学习领域的一些现代发展。
- **内容风格**

  - **每章结构**：每章的大部分内容以要点形式呈现。为了帮助您快速理解每个部分的核心内容，关键文本块会以加粗的单词或短语开头（如您正在阅读的这段）。您可以将其视为段落的小标题。
  - **可选内容**：标有$\star$的部分或段落为选读内容。如果您时间有限或只想专注于核心知识点，可以跳过这些内容。
  - **待定义概念**：所有需要进一步解释的术语或概念都以$\textit{斜体文本}$形式呈现。
  - **符号说明**：

    - 带时间步下标的大写字母表示随机变量，例如$A_t$。

      - 在算法展示中，大写字母（不带下标）用于表示随机变量的实际值。
    - 小写字母（带或不带下标）表示相应随机变量的具体实例。例如，$s$是状态集合$S$中的一个特定状态，$s_t$表示时间步$t$的状态（同理，$s_0$、$s_1$等依此类推）。
- **学习建议**

  - **如何结合书籍与在线课程（视频）**：我的目标是融合RL入门书和Coursera讲座视频的精华，让学习过程更加轻松。具体做法如下：

    - 对于复杂的数学推导，我同时提供文本解释和视频讲解。您可以选择最适合自己的学习方式。
    - 对于逐步演示，我添加了视频截图以加快阅读速度。完整的讲座视频通常会作为可选材料提供，供您深入学习。
    - 对于问题示例（从介绍到解决方案），我主要使用视频讲解，因为视频能更清晰地展示解题过程。这些内容以可点击的截图形式嵌入，有时我会在下方添加简短笔记，突出关键要点。
  - **如何提升学习效果**：您可以考虑使用支持网络搜索的语言模型（LLM）工具作为个人学习助手，让它帮助您理解复杂概念。就是这么简单！

## 其他学习资源推荐

为了帮助强化学习（RL）爱好者更有效地学习，我整理了本教程。但每个人都有自己独特的学习方式，因此，以下是一些我认为同样优秀的资源，或许能在您的RL学习之旅中助一臂之力：

- [Tim Miller教授编写的在线RL书籍](https://gibberblot.github.io/rl-notes/index.html)
- [OpenAI Spinning Up](https://spinningup.openai.com/en/latest/index.html)（更适合有一定深度学习基础的学习者）
- [Hugging Face深度RL课程](https://huggingface.co/learn/deep-rl-course/unit0/introduction)（您甚至可以在这里获得证书）
- [David Silver在UCL的RL课程](https://www.youtube.com/playlist?list=PLqYmG7hTraZDM-OYHWgPebj2MfCFzFObQ)（我的个人最爱）
- 一些RL学习笔记（类似速查表）：

  - [Scott Jeen的PDF笔记](https://enjeeneer.io/sutton_and_barto/rl_notes.pdf)
  - [Blog IndoML的笔记](https://indoml.com/2018/02/14/study-notes-reinforcement-learning-an-introduction/#:~:text=The%20main%20elements%20of%20RL,a%20model%20of%20the%20environment.&text=The%20learner%2Fdecision%20maker%20being%20trained.)
  - [Luciano Strika的笔记](https://strikingloo.github.io/wiki/reinforcement-learning-sutton)
- [Github awesome-deep-rl](https://github.com/kengz/awesome-deep-rl)

最后需要说明的是，由于强化学习本身的复杂性，初学者往往会感到学习曲线异常陡峭。您可以在Reddit上进一步提问，或在Coursera等学习平台上寻找其他课程，总能找到最适合自己的学习资源。

## 感谢与建议

关于我（作者）的更多信息，您可以通过[我的GitHub个人主页](https://github.com/Dong237)或[LinkedIn](https://www.linkedin.com/in/youxiang-dong-6986bb211/)了解。

我要向[Marvin Schweizer](https://github.com/mschweizer)致以诚挚的感谢，感谢他为这个项目提供了宝贵的反馈！

这个项目还有很多需要改进的地方，我非常期待听到您的想法。欢迎随时在GitHub上提交issue分享您的建议——您的每一条反馈都将帮助这个资源变得更好，惠及更多学习者。
